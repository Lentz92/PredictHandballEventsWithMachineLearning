---
title: "02-FinalXgBoostModel"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.height = 10,
  fig.width = 25,
  message = FALSE,
  warning = FALSE
)

library(tidyverse)
library(tidymodels)
tidymodels_prefer()
library(doSNOW)
library(finetune)
library(latex2exp)
library(patchwork)
source("confusionMatrixFromList.R")
ggthemr::ggthemr("greyscale")

loadRData <- function(fileName){
  #loads an RData file, and returns it
  load(fileName)
  get(ls()[ls() != "fileName"])
}

#Import results from the most important variables and the main df

selectedFeatures <- loadRData(file = "../../data/processed/VSURF/combination_selectedfeatures_multiclass.Rdata")
selectedFeatures <- 
  #Convert the nested list of vectors to one long vector in a tibble
  tibble(features = unlist(selectedFeatures)) %>% 
  #count number of occurences of each feature
  count(features) %>% 
  #select only the features that was present for more than 6 athletes
  filter(n >= 6)


dfMappings <- data.table::fread("../../data/processed/dfMappingsAllTags.csv") %>% 
  filter(Tag != "RESET")

df <- dfMappings %>% 
  mutate(
    Tag = factor(Tag, levels = c("Low Intensity","Dynamic","Running","Throw")),
    Subject = factor(Subject)
    )
```

## MODEL

```{r}
j = 1
xgbFitted <- list()
xgbTrainResults <- list()
xgbTestResults <- list()
#Modelling over the training set 12 times, with a new subject pulled out as a test set each time
#ending up with 12 trained models.
for (i in unique(df$Subject)){

  start_time = Sys.time()
  print(glue::glue("Model {j} out of {length(unique(df$Subject))}"))
  
  #Data split based on leave-one-subject-out approach
  dfTest <- df %>%
    filter(Subject == i) %>% 
    select(Subject, Tag, all_of(selectedFeatures$features))
  
  dfTrain <- df %>%
    filter(Subject != i) %>% 
    select(Subject, Tag, all_of(selectedFeatures$features))
  
  df_folds <- vfold_cv(dfTrain, v = 10, strata = Tag)
  
  #Create recipe
  rec <-
    recipe(formula = Tag ~ ., data = dfTrain) %>% 
    step_rm(Subject)
  
  # -- Xgboost -- #
  xgb_spec <- 
    boost_tree(tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(), 
               min_n = tune(), sample_size = tune(), trees = tune()) %>% 
    set_engine("xgboost") %>% 
    set_mode("classification")
  
  #Create workflow
  xgb_workflow <- workflow(rec, xgb_spec)
  
  #Multi-thread processing  
  cl <- parallel::makePSOCKcluster(6)
  doParallel::registerDoParallel(cl)

  #Hyperparameter tuning  
  set.seed(345)
  xgb_rs <- tune_race_anova(
    xgb_workflow,
    resamples = df_folds,
    grid = 25, 
    #f_meas is the metric that defines which model is the best, however roc_auc has also been added
    #to make the tuning return the posterior probability for each class decision.
    metrics = metric_set(f_meas, roc_auc),
    control = control_race(save_pred = TRUE,
                           parallel_over = "everything",
                           save_workflow = TRUE)
  )
  
  stopCluster(cl)
  registerDoSEQ()

  
  #Select best and finalize the workflow
  best_xgb <- xgb_rs %>% 
    select_best("f_meas")
  
  final_xgb_workflow <- 
    xgb_workflow %>% 
    finalize_workflow(best_xgb)
  
  fit_xgb <- 
    fit(final_xgb_workflow, dfTrain)
  
  #Save the tuned model
  xgbFitted[[j]] <- fit_xgb
  
  #Predict on the training data, to learn if the model overfits
  prediction <- predict(fit_xgb, dfTrain)
  prob_prediction <- predict(fit_xgb, dfTrain, type = "prob")
  
  #combining everything into one need dataframe.
  Trainvalidated <- data.frame(
    class = dfTrain$Tag,
    .pred_class = prediction$.pred_class
  ) %>% 
    cbind(prob_prediction)
  
  xgbTrainResults[[j]] <- Trainvalidated
  
  #Predict on test set
  prediction <- predict(fit_xgb, dfTest)
  prob_prediction <- predict(fit_xgb, dfTest, type = "prob")
  
  #combining everything into one need dataframe.
  Testvalidated <- data.frame(
    class = dfTest$Tag,
    .pred_class = prediction$.pred_class
  ) %>% 
    cbind(prob_prediction)
  
  xgbTestResults[[j]] <- Testvalidated
  
  j = j + 1
  
  end_time = Sys.time()
  print(end_time - start_time)
  
}

save(xgbFitted, file = "data/xgbFitted_multiclass.R")
save(xgbTrainResults, file = "data/xgbTrainResults_multiclass.R")
save(xgbTestResults, file = "data/xgbTestResults_multiclass.R")


```

# Look into the test results

```{r}
xgbTestResultsMulticlass <- loadRData("data/xgbTestResults_multiclass.R")
confusionMatrixFromList(xgbTestResultsMulticlass)

ggsave("confusionMatrix.png", width = 20, heigh = 12, dpi = 600)
```

```{r}
#Calculate F1-score for each model iteration. 
caretConfusionMatrix <- list()
for (i in 1:12){
  data <- xgbTestResultsMulticlass[[i]] %>% 
    janitor::clean_names()
  
  cm <- caret::confusionMatrix(data = data$pred_class, reference = data$class, mode = "everything")
  caretConfusionMatrix[[i]] <- cm
  
}

caretConfusionMatrix[[2]]

```

```{r}
#Multiclass AUC function for each class
AUCmulticlass <- function(data){
  
  data_class <- data %>% 
    janitor::clean_names() %>% 
    mutate(twoClass = as_factor(ifelse(class == "Low Intensity", "Low Intensity", "Other")),
           pred_other = pred_throw + pred_dynamic + pred_running) %>% 
    roc_auc(twoClass, pred_low_intensity)
  
  print(glue::glue("OvR -- Low Intensity: {data_class}"))
  
  data_class <- data %>% 
    janitor::clean_names() %>% 
    mutate(twoClass = as_factor(ifelse(class == "Dynamic", "Dynamic", "Other")),
           pred_other = pred_low_intensity + pred_throw + pred_running) %>% 
    roc_auc(twoClass, pred_other)
  
  print(glue::glue("OvR -- Dynamic: {data_class}"))
  
  data_class <- data %>% 
    janitor::clean_names() %>% 
    mutate(twoClass = as_factor(ifelse(class == "Running", "Running", "Other")),
           pred_other = pred_low_intensity + pred_dynamic + pred_throw) %>% 
    roc_auc(twoClass, pred_other)
  
  print(glue::glue("OvR -- Running: {data_class}"))
  
  data_class <- data %>% 
    janitor::clean_names() %>% 
    mutate(twoClass = as_factor(ifelse(class == "Throw", "Throw", "Other")),
           pred_other = pred_low_intensity + pred_dynamic + pred_running) %>% 
    roc_auc(twoClass, pred_other)
  
  print(glue::glue("OvR -- Throw: {data_class}"))
  
  
}

AUCmulticlass(xgbTestResultsMulticlass[[1]])
```

```{r}
xgbTestResultsMulticlass[[12]] %>% 
  janitor::clean_names() %>% 
  roc_curve(class, pred_low_intensity:pred_throw) %>% 
  autoplot() + 
  ggtitle("Subject 12")
```

```{r}
xgbTestResultsMulticlass_binded <- xgbTestResultsMulticlass %>% 
  bind_rows() %>% 
  distinct() %>% 
  janitor::clean_names()

AUCmulticlass(xgbTestResultsMulticlass_binded)
caret::confusionMatrix(data = xgbTestResultsMulticlass_binded$pred_class, 
                       reference = xgbTestResultsMulticlass_binded$class, 
                       mode = "everything")


f_meas(data = xgbTestResultsMulticlass_binded, truth = class, estimate = pred_class, estimator = "macro_weighted")

sens(data = xgbTestResultsMulticlass_binded, truth = class, estimate = pred_class, estimator = "macro_weighted")

spec(data = xgbTestResultsMulticlass_binded, truth = class, estimate = pred_class, estimator = "macro_weighted")

roc_auc(data = xgbTestResultsMulticlass_binded, truth = class, pred_low_intensity:pred_throw,
        estimator = "macro_weighted")
```

# Variable importance

```{r}
xgbFittedMulticlass <- loadRData(file = "data/xgbFitted_multiclass.R")

#Combine variable importance lists
variableImportanceList <- list()

for (i in 1:12){
  
  vi <- xgbFittedMulticlass[[i]] %>% 
    extract_fit_parsnip() %>% 
    vip::vi() %>% 
    mutate(
      n = 1:n(),
      weight = paste(Variable, n, sep="_")
      )
    
  variableImportanceList[[i]] <- vi$weight
}

```

```{r}
mostFreqFeatures <- 
  #Convert the nested list of vectors to one long vector in a tibble
  tibble(features = unlist(variableImportanceList)) %>% 
  count(features) %>% 
  mutate(imp = as.numeric(sub(".*_", "", features))) %>% 
  filter(imp <= 10)

mostFreqFeatures %>% view()
```

```{r}
dfMappings %>% 
  ggplot(aes(x = magnitude_max, energyPeakUp, color = Tag)) + 
  geom_point(alpha = 0.5, size = 3) + 
  scale_color_manual(values = c("blue","green","orange","purple")) + 
  labs(x = "Max value for Acceleration Magnitude",
       y = "Peak power for Up Acceleration",
       color = "Event") + 
  theme(legend.position = "top",
        text = element_text(size = 35),
        legend.title = element_text(size = 35, face = "bold"),
        legend.key.size = unit(3, 'cm'),
        axis.title = element_text(size = 40, face = "bold"),
  ) +
  guides(color = guide_legend(override.aes = list(size = 10)))

ggsave("magMaxvsPeakUp.png", width = 20, heigh = 12, dpi = 300)
```

```{r}
plotReady <- dfMappings %>% 
  select(Tag, contains("Peak")) %>% 
  rename(
    Forward = "energyPeakForward",
    Upward = "energyPeakUp",
    Side = "energyPeakSide",
    Roll = "energyPeakRoll",
    Pitch = "energyPeakPitch",
    Yaw = "energyPeakYaw",
    "Acceleration Magnitude" = "energyPeakMagnitude",
    "Rotation Magnitude" = "energyrotPeakMagnitude"
  )

p1 <- plotReady %>% 
  pivot_longer(cols = c("Forward", "Upward", "Side", "Acceleration Magnitude")) %>% 
  mutate(name = factor(name, levels=c("Forward",
                                      "Side",
                                      "Upward",
                                      "Acceleration Magnitude"))) %>% 
  ggplot(aes(x = Tag, y = value, color = Tag)) + 
  ggbeeswarm::geom_quasirandom(alpha=0.5) +
  facet_wrap(~name, scale = "free", ncol = 1) + 
  scale_color_manual(values = c("blue","green","orange","purple")) + 
  labs(x = "",
       y = TeX("Acceleration [$m\\cdot s^{-2}$]")) + 
  theme(legend.position = "none",
        text = element_text(size = 25),
        axis.title = element_text(size = 30, face = "bold"),
  ) +
  guides(color = guide_legend(override.aes = list(size = 10)))

p2 <- plotReady %>% 
  pivot_longer(cols = c("Roll", "Pitch", "Yaw", "Rotation Magnitude")) %>% 
  mutate(name = factor(name, levels=c("Roll",
                                      "Pitch",
                                      "Yaw",
                                      "Rotation Magnitude"))) %>% 
  ggplot(aes(x = Tag, y = value, color = Tag)) + 
  ggbeeswarm::geom_quasirandom(alpha=0.5) +
  facet_wrap(~name, scale = "free", ncol = 1) + 
  scale_color_manual(values = c("blue","green","orange","purple")) + 
  labs(x = "",
       y = TeX("Angular rotation [degree$\\cdot s^{-1}$]")) + 
  theme(legend.position = "none",
        text = element_text(size = 25),
        axis.title = element_text(size = 30, face = "bold"),
  ) +
  guides(color = guide_legend(override.aes = list(size = 10)))

finalPlot <- p1 + p2 +plot_annotation(tag_levels ="A")
ggsave("PeakPowerSwarmplot.png", plot = finalPlot, width = 20, heigh = 12, dpi = 300)

```
